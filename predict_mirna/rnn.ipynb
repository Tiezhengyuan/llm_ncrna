{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b565e68",
   "metadata": {},
   "source": [
    "## prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "123ffe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "f53d0aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UGAGGUAGUAGGUUGUAUAGUU Caenorhabditis elegans\n"
     ]
    }
   ],
   "source": [
    "# retrieve sequences and species as label\n",
    "from Bio import SeqIO\n",
    "\n",
    "infile = 'mature.fa'\n",
    "# infile = 'hairpin.fa'\n",
    "\n",
    "def iterate_data(infile:str):\n",
    "    with open(infile, 'r') as f:\n",
    "        parser = SeqIO.parse(f, 'fasta')\n",
    "        for rec in parser:\n",
    "            seq = str(rec.seq)\n",
    "            specie = ' '.join(rec.description.split(' ')[2:4])\n",
    "            yield seq, specie\n",
    "\n",
    "data_iter = iterate_data(infile)\n",
    "seq, specie = next(data_iter)\n",
    "print(seq, specie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a0a9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for seq, specie in iterate_data(infile):\n",
    "    train_data.append((specie, ''.join(seq)))\n",
    "print(train_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "93eef4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([21, 8, 7, 2, 18, 8, 5, 7, 8, 3, 10, 2, 10, 0], [4, 3, 3, 3, 3, 4, 3, 4, 5, 4, 4, 2, 5, 2, 3, 2, 5, 2, 4, 5, 4, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "39108 <class 'torch.utils.data.dataset.Subset'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataset.Subset at 0x75d48c937040>,\n",
       " <torch.utils.data.dataset.Subset at 0x75d48c92a880>)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyEmbedding:\n",
    "    def __init__(self, data:list):\n",
    "        self.data = data\n",
    "        self.train_dataset, self.valid_dataset = None, None\n",
    "    \n",
    "    def split(self):\n",
    "        num_train = round(len(self.data)*.8)\n",
    "        num_valid = len(self.data) - num_train\n",
    "        self.train_dataset, self.valid_dataset = random_split(self.data, [num_train, num_valid])\n",
    "        print(self.train_dataset[0])\n",
    "        print(len(self.train_dataset), type(self.train_dataset))\n",
    "        return self.train_dataset, self.valid_dataset\n",
    "\n",
    "torch.manual_seed(1)\n",
    "me = MyEmbedding(train_data)\n",
    "me.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975b1431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e894ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "64987716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Caenorhabditis elegans', 'UGAGGUAGUAGGUUGUAUAGUU')\n",
      "('Melibe leonina', 'AGGGGAGACAAUCUGUCUACAUG')\n",
      "39108 <class 'torch.utils.data.dataset.Subset'>\n"
     ]
    }
   ],
   "source": [
    "train_dataset = []\n",
    "for seq, specie in iterate_data(infile):\n",
    "    train_dataset.append((specie, ''.join(seq)))\n",
    "print(train_dataset[0])\n",
    "\n",
    "torch.manual_seed(1)\n",
    "# args:dataset: list type\n",
    "num_train = round(len(train_dataset)*.8)\n",
    "num_valid = len(train_dataset) - num_train\n",
    "train_dataset, valid_dataset = random_split(train_dataset, [num_train, num_valid])\n",
    "print(train_dataset[0])\n",
    "print(len(train_dataset), type(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "ff18c64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A sentence converted to tokens: UGUGUGUUCCGCUUCUUCUUU ['U', 'G', 'U', 'G', 'U', 'G', 'U', 'U', 'C', 'C', 'G', 'C', 'U', 'U', 'C', 'U', 'U', 'C', 'U', 'U', 'U']\n",
      "Vocab-size: 4\n"
     ]
    }
   ],
   "source": [
    "## Step 2 tokenization: unique tokens (words)\n",
    "from collections import Counter\n",
    "\n",
    "# slice sentence by word.\n",
    "def tokenizer(text:str):\n",
    "    return list(text)\n",
    "#     step, res = 6, []\n",
    "#     for i in range(0, len(text)-step+1):\n",
    "#         res.append(text[i:i+step])\n",
    "#     return res\n",
    "\n",
    "# count tokens\n",
    "token_counts = Counter()\n",
    "for label, line in train_dataset:\n",
    "    tokens = tokenizer(line)\n",
    "    # words in list type\n",
    "    token_counts.update(tokens)\n",
    "\n",
    "print('A sentence converted to tokens:', line, tokens)\n",
    "print('Vocab-size:', len(token_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "59e37b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab-size of labels: 262\n"
     ]
    }
   ],
   "source": [
    "# count tokens of output\n",
    "label_token_counts = Counter()\n",
    "for label, line in train_dataset:\n",
    "    # words in list type\n",
    "    label_token_counts.update([label,])\n",
    "\n",
    "print('Vocab-size of labels:', len(label_token_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "443a7177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('U', 243537), ('G', 218676), ('A', 205596), ('C', 186588)])\n",
      "counts: [243537, 218676, 205596, 186588]\n"
     ]
    }
   ],
   "source": [
    "# sort token couts\n",
    "from collections import OrderedDict\n",
    "\n",
    "sorted_by_freq_tuples = sorted(token_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "# descending sort counts\n",
    "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
    "print(ordered_dict)\n",
    "counts = list(ordered_dict.values())\n",
    "print('counts:', counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "d064a193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts: [2098, 1579, 989, 904, 817, 721, 627, 606, 597, 597, 564, 543, 520, 519, 504, 500, 492, 473, 467, 466, 463, 458, 440, 439, 416, 392, 392, 390, 375, 375, 369, 368, 356, 355, 347, 341, 337, 328, 328, 326, 321, 312, 304, 304, 301, 295, 293, 285, 281, 271, 270, 260, 250, 242, 240, 238, 227, 220, 209, 204, 204, 202, 199, 180, 179, 178, 177, 176, 175, 170, 167, 157, 154, 154, 152, 151, 151, 148, 147, 147, 145, 144, 143, 143, 142, 138, 135, 135, 133, 133, 131, 127, 125, 125, 123, 122, 120, 120, 118, 117, 116, 113, 110, 109, 108, 104, 103, 102, 102, 100, 100, 97, 96, 95, 93, 90, 88, 83, 81, 81, 80, 78, 78, 76, 74, 74, 73, 71, 71, 70, 67, 66, 66, 66, 64, 63, 61, 60, 57, 57, 57, 56, 56, 56, 56, 55, 55, 54, 54, 53, 51, 51, 50, 46, 43, 43, 41, 40, 40, 39, 38, 38, 38, 35, 35, 34, 33, 33, 32, 30, 30, 30, 30, 29, 28, 26, 25, 25, 25, 24, 24, 24, 22, 21, 21, 20, 19, 18, 18, 17, 17, 16, 16, 15, 14, 14, 14, 14, 14, 13, 13, 13, 13, 12, 12, 12, 11, 11, 10, 10, 9, 8, 8, 8, 8, 7, 7, 7, 7, 7, 7, 6, 6, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "label_sorted_by_freq_tuples = sorted(label_token_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "# descending sort counts\n",
    "label_ordered_dict = OrderedDict(label_sorted_by_freq_tuples)\n",
    "# print(label_ordered_dict)\n",
    "label_counts = list(label_ordered_dict.values())\n",
    "print('counts:', label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "67a40040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab()\n"
     ]
    }
   ],
   "source": [
    "## Step 3 encoding: encoding each unique token into integers\n",
    "from torchtext.vocab import vocab\n",
    "\n",
    "# convert count value to index value (ranking)\n",
    "input_vocab = vocab(ordered_dict)\n",
    "input_vocab.insert_token(\"<pad>\", 0)\n",
    "input_vocab.insert_token(\"<unk>\", 1)\n",
    "# default token is \"<unk>\"\n",
    "input_vocab.set_default_index(1)\n",
    "print(input_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "141effc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homo sapiens 2\n",
      "Mus musculus 3\n",
      "Gallus gallus 4\n",
      "Monodelphis domestica 5\n",
      "<pad> 0\n",
      "<unk> 1\n"
     ]
    }
   ],
   "source": [
    "# convert count value to index value (ranking)\n",
    "label_vocab = vocab(label_ordered_dict)\n",
    "# print(label_ordered_dict)\n",
    "label_vocab.insert_token(\"<pad>\", 0)\n",
    "label_vocab.insert_token(\"<unk>\", 1)\n",
    "# default token is \"<unk>\"\n",
    "label_vocab.set_default_index(1)\n",
    "for s in top_species+ ['<pad>', '<unk>']:\n",
    "    print(s, label_vocab[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "b536e723",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 3-A: define the functions for transformation\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# feed a tokens vector representing one sentence \n",
    "text_pipeline = lambda x: [input_vocab[token] for token in tokenizer(x)]\n",
    "label_pipeline = lambda x: label_vocab[x] if x in top_species else 1\n",
    "\n",
    "# # format label: label = 1, 0\n",
    "# import torchtext\n",
    "# from torchtext import __version__ as torchtext_version\n",
    "# from pkg_resources import parse_version\n",
    "# if parse_version(torchtext.__version__) > parse_version(\"0.10\"):\n",
    "#     label_pipeline = lambda x: 1. if x == 2 else 0.         # 1 ~ negative, 2 ~ positive review\n",
    "# else:\n",
    "#     label_pipeline = lambda x: 1. if x == 'Homo sapiens' else 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "7c185c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 3-B: wrap the encode and transformation function\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, lengths = [], [], []\n",
    "    for _label, _text in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        lengths.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.float32)\n",
    "    lengths = torch.tensor(lengths)\n",
    "    # padding is appended to the end of token vector of each sentence\n",
    "    padded_text_list = nn.utils.rnn.pad_sequence(text_list, batch_first=True)\n",
    "#     print(label_list)\n",
    "    return padded_text_list.to(device), label_list.to(device), lengths.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "de241851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Melibe leonina', 'AGGGGAGACAAUCUGUCUACAUG')"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "0dc87ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "input: torch.Size([4, 23])\n",
      "output: tensor([1., 1., 1., 1.], device='cuda:0')\n",
      "batch size= tensor([23, 21, 21, 21], device='cuda:0')\n",
      "tensor([[4, 3, 3, 3, 3, 4, 3, 4, 5, 4, 4, 2, 5, 2, 3, 2, 5, 2, 4, 5, 4, 2, 3],\n",
      "        [2, 3, 5, 5, 2, 3, 3, 5, 2, 5, 5, 5, 2, 3, 2, 4, 2, 3, 5, 5, 4, 0, 0],\n",
      "        [3, 4, 4, 3, 2, 3, 2, 3, 5, 2, 3, 2, 3, 3, 2, 3, 2, 3, 2, 5, 2, 0, 0],\n",
      "        [2, 4, 2, 2, 5, 3, 4, 3, 5, 5, 4, 4, 2, 4, 4, 3, 2, 2, 5, 3, 3, 0, 0]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# study dataloader: load dataset into dataloader with collate function\n",
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(train_dataset, batch_size=4, shuffle=False, collate_fn=collate_batch)\n",
    "print(type(dataloader))\n",
    "\n",
    "##Observe data dimensions: Take a small batch\n",
    "text_batch, label_batch, length_batch = next(iter(dataloader))\n",
    "# one batch = one sentence (218 words)\n",
    "print('input:', text_batch.shape)\n",
    "print('output:', label_batch)\n",
    "print('batch size=', length_batch)\n",
    "\n",
    "print(text_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "b7aa452c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 4: batching the datasets. shuffle data for each epoch\n",
    "batch_size = 32\n",
    "\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "valid_dl = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "55bee5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, embed_dim, rnn_hidden_size, fc_hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_size, embed_dim, padding_idx=0) \n",
    "        # model: long-short term memory\n",
    "        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size, num_layers=2, batch_first=True)\n",
    "        self.fc1 = nn.Linear(rnn_hidden_size, fc_hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(fc_hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, text, lengths):\n",
    "        out = self.embedding(text)\n",
    "        # Packs a Tensor containing padded sequences of variable length.\n",
    "        lengths = lengths.cpu().numpy()\n",
    "        out = nn.utils.rnn.pack_padded_sequence(out, lengths, batch_first=True, enforce_sorted=False)\n",
    "        # \n",
    "        out, (hidden, cell) = self.rnn(out)\n",
    "        out = hidden[-1, :, :]\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "         \n",
    "vocab_size = len(input_vocab)\n",
    "print(embedding_dim)\n",
    "embed_dim = 24\n",
    "rnn_hidden_size = 32\n",
    "fc_hidden_size = 32\n",
    "\n",
    "torch.manual_seed(1)\n",
    "model = RNN(vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size) \n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "bbac6fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    total_acc, total_loss = 0, 0\n",
    "    for text_batch, label_batch, lengths in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(text_batch, lengths)[:, 0]\n",
    "        loss = loss_fn(pred, label_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_acc += ((pred>=0.5).float() == label_batch).float().sum().item()\n",
    "        total_loss += loss.item()*label_batch.size(0)\n",
    "    return total_acc/len(dataloader.dataset), total_loss/len(dataloader.dataset)\n",
    " \n",
    "def evaluate(model, dataloader, loss_fn, optimizer):\n",
    "    model.eval()\n",
    "    total_acc, total_loss = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for text_batch, label_batch, lengths in dataloader:\n",
    "            pred = model(text_batch, lengths)[:, 0]\n",
    "            loss = loss_fn(pred, label_batch)\n",
    "            total_acc += ((pred>=0.5).float() == label_batch).float().sum().item()\n",
    "            total_loss += loss.item()*label_batch.size(0)\n",
    "    return total_acc/len(dataloader.dataset), total_loss/len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "27327378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 accuracy: 0.8576 val_accuracy: 0.8530\n",
      "Epoch 1 accuracy: 0.8576 val_accuracy: 0.8530\n",
      "Epoch 2 accuracy: 0.8576 val_accuracy: 0.8530\n",
      "Epoch 3 accuracy: 0.8576 val_accuracy: 0.8530\n",
      "Epoch 4 accuracy: 0.8576 val_accuracy: 0.8530\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "torch.manual_seed(1)\n",
    " \n",
    "for epoch in range(num_epochs):\n",
    "    acc_train, loss_train = train(model, train_dl, loss_fn, optimizer)\n",
    "    acc_valid, loss_valid = evaluate(model, valid_dl, loss_fn, optimizer)\n",
    "    print(f'Epoch {epoch} accuracy: {acc_train:.4f} val_accuracy: {acc_valid:.4f}')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dbe0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "c169cc85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(4098, 24, padding_idx=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 1.1017e+00, -1.7594e-01, -2.2456e+00,  ..., -1.0373e+00,\n",
       "          1.5748e+00, -6.2985e-01],\n",
       "        [-9.1478e-01,  5.4887e-01,  4.5846e-02,  ...,  1.1136e-03,\n",
       "          1.6815e+00, -1.6467e-02],\n",
       "        ...,\n",
       "        [ 6.7938e-01,  8.2085e-02,  2.1721e-01,  ...,  2.1112e-01,\n",
       "          1.5892e+00,  2.2728e-01],\n",
       "        [ 7.3429e-01, -5.5941e-01, -3.9502e-01,  ..., -4.6106e-02,\n",
       "          9.6702e-01,  1.0417e+00],\n",
       "        [-3.5593e-01,  2.0741e+00, -1.5004e-01,  ..., -7.1639e-01,\n",
       "          1.3424e+00,  5.3942e-01]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.embedding)\n",
    "model.embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "63ebf281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.to of RNN(\n",
       "  (embedding): Embedding(4098, 24, padding_idx=0)\n",
       "  (rnn): LSTM(24, 32, num_layers=2, batch_first=True)\n",
       "  (fc1): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")>"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37af4cb3",
   "metadata": {},
   "source": [
    "## pre-trained RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "aecf89ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Caenorhabditis elegans', 'UGAGGUAGUAGGUUGUAUAGUU')\n",
      "('pseudo', 'CGGGGCAGCUCAGUACAAGACG')\n",
      "78216 <class 'torch.utils.data.dataset.Subset'>\n"
     ]
    }
   ],
   "source": [
    "# dataset\n",
    "import random\n",
    "\n",
    "pre_train_dataset = []\n",
    "for seq, specie in iterate_data(infile):\n",
    "    pre_train_dataset.append((specie, seq))\n",
    "    random.shuffle(list(seq))\n",
    "    pre_train_dataset.append(('pseudo', ''.join(seq)))\n",
    "print(pre_train_dataset[0])\n",
    "\n",
    "torch.manual_seed(1)\n",
    "# args:dataset: list type\n",
    "num_train = round(len(pre_train_dataset)*.8)\n",
    "num_valid = len(pre_train_dataset) - num_train\n",
    "pre_train_dataset, pre_valid_dataset = random_split(pre_train_dataset, [num_train, num_valid])\n",
    "print(pre_train_dataset[0])\n",
    "print(len(pre_train_dataset), type(pre_train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "36dd7512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A sentence converted to tokens: GGUGGAUAUUCCUUCUAUGUUU ['G', 'G', 'U', 'G', 'G', 'A', 'U', 'A', 'U', 'U', 'C', 'C', 'U', 'U', 'C', 'U', 'A', 'U', 'G', 'U', 'U', 'U']\n",
      "Vocab-size: 4\n"
     ]
    }
   ],
   "source": [
    "## Step 2 tokenization: unique tokens (words)\n",
    "from collections import Counter\n",
    "\n",
    "# slice sentence by word.\n",
    "def tokenizer(text:str):\n",
    "    return list(text)\n",
    "\n",
    "# count tokens\n",
    "pre_token_counts = Counter()\n",
    "for label, line in pre_train_dataset:\n",
    "    tokens = tokenizer(line)\n",
    "    # words in list type\n",
    "    pre_token_counts.update(tokens)\n",
    "\n",
    "print('A sentence converted to tokens:', line, tokens)\n",
    "print('Vocab-size:', len(pre_token_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "194e17ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab-size of labels: 261\n"
     ]
    }
   ],
   "source": [
    "# count tokens of output\n",
    "pre_label_token_counts = Counter()\n",
    "for label, line in pre_train_dataset:\n",
    "    # words in list type\n",
    "    pre_label_token_counts.update([label,])\n",
    "\n",
    "print('Vocab-size of labels:', len(pre_label_token_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "49409ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('U', 243537), ('G', 218676), ('A', 205596), ('C', 186588)])\n",
      "counts: [243537, 218676, 205596, 186588]\n"
     ]
    }
   ],
   "source": [
    "# sort token couts\n",
    "from collections import OrderedDict\n",
    "\n",
    "pre_sorted_by_freq_tuples = sorted(token_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "# descending sort counts\n",
    "pre_ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
    "print(pre_ordered_dict)\n",
    "pre_counts = list(pre_ordered_dict.values())\n",
    "print('counts:', pre_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "1e098f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts: [39039, 2120, 1598, 1006, 914, 836, 737, 621, 612, 599, 585, 540, 540, 524, 523, 520, 502, 490, 480, 472, 468, 466, 465, 458, 443, 426, 415, 402, 382, 377, 376, 370, 365, 363, 359, 351, 348, 341, 334, 327, 315, 311, 311, 309, 298, 292, 290, 279, 274, 266, 265, 261, 260, 257, 248, 242, 239, 232, 226, 209, 206, 205, 201, 193, 192, 186, 177, 177, 174, 173, 171, 166, 161, 159, 153, 151, 147, 147, 146, 146, 144, 143, 140, 140, 140, 139, 136, 134, 133, 133, 133, 129, 129, 128, 126, 126, 125, 123, 121, 119, 118, 117, 117, 113, 111, 111, 106, 100, 98, 96, 96, 96, 95, 95, 95, 95, 93, 93, 88, 83, 83, 82, 80, 78, 76, 75, 73, 71, 69, 66, 64, 64, 63, 61, 61, 60, 60, 59, 59, 58, 58, 57, 56, 56, 55, 55, 53, 52, 52, 51, 51, 50, 50, 48, 47, 45, 42, 42, 42, 42, 41, 41, 39, 39, 37, 36, 35, 33, 31, 30, 29, 28, 28, 28, 26, 25, 24, 24, 24, 24, 24, 23, 23, 21, 21, 21, 21, 20, 20, 19, 18, 17, 16, 16, 15, 15, 14, 14, 13, 13, 12, 12, 12, 11, 11, 11, 11, 11, 10, 10, 10, 10, 9, 8, 7, 7, 7, 7, 7, 7, 6, 5, 5, 5, 5, 5, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "pre_label_sorted_by_freq_tuples = sorted(pre_label_token_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "# descending sort counts\n",
    "pre_label_ordered_dict = OrderedDict(pre_label_sorted_by_freq_tuples)\n",
    "# print(label_ordered_dict)\n",
    "pre_label_counts = list(pre_label_ordered_dict.values())\n",
    "print('counts:', pre_label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "77d8f7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab()\n"
     ]
    }
   ],
   "source": [
    "## Step 3 encoding: encoding each unique token into integers\n",
    "from torchtext.vocab import vocab\n",
    "\n",
    "# convert count value to index value (ranking)\n",
    "pre_input_vocab = vocab(pre_ordered_dict)\n",
    "pre_input_vocab.insert_token(\"<pad>\", 0)\n",
    "pre_input_vocab.insert_token(\"<unk>\", 1)\n",
    "# default token is \"<unk>\"\n",
    "pre_input_vocab.set_default_index(1)\n",
    "print(pre_input_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b91871a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert count value to index value (ranking)\n",
    "pre_label_vocab = vocab(pre_label_ordered_dict)\n",
    "# print(label_ordered_dict)\n",
    "label_vocab.insert_token(\"<pad>\", 0)\n",
    "label_vocab.insert_token(\"<unk>\", 1)\n",
    "# default token is \"<unk>\"\n",
    "label_vocab.set_default_index(1)\n",
    "for s in top_species+ ['<pad>', '<unk>']:\n",
    "    print(s, label_vocab[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d746d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8525a0d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baba0d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074097a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657f7ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "d21df606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2355\n"
     ]
    }
   ],
   "source": [
    "class RNN1(nn.Module):\n",
    "    def __init__(self, input_size, embed_dim, rnn_hidden_size, fc_hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_size, embed_dim, padding_idx=0) \n",
    "        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size, num_layers=2, batch_first=True)\n",
    "        self.fc1 = nn.Linear(rnn_hidden_size, fc_hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, text, lengths):\n",
    "        out = self.embedding(text)\n",
    "        # Packs a Tensor containing padded sequences of variable length.\n",
    "        lengths = lengths.cpu().numpy()\n",
    "        out = nn.utils.rnn.pack_padded_sequence(out, lengths, batch_first=True, enforce_sorted=False)\n",
    "        # \n",
    "        out, (hidden, cell) = self.rnn(out)\n",
    "        out = hidden[-1, :, :]\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "         \n",
    "vocab_size = len(input_vocab)\n",
    "print(embedding_dim)\n",
    "embed_dim = 24\n",
    "rnn_hidden_size = 32\n",
    "fc_hidden_size = 32\n",
    "\n",
    "torch.manual_seed(1)\n",
    "model1 = RNN1(vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size) \n",
    "model1 = model1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "6612c07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2355\n"
     ]
    }
   ],
   "source": [
    "class RNN2(nn.Module):\n",
    "    def __init__(self, model1, input_size, embed_dim, rnn_hidden_size, fc_hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = model1.embedding\n",
    "        # model: long-short term memory\n",
    "        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size, num_layers=2, batch_first=True)\n",
    "        self.fc1 = nn.Linear(rnn_hidden_size, fc_hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(fc_hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, text, lengths):\n",
    "        out = self.embedding(text)\n",
    "        # Packs a Tensor containing padded sequences of variable length.\n",
    "        lengths = lengths.cpu().numpy()\n",
    "        out = nn.utils.rnn.pack_padded_sequence(out, lengths, batch_first=True, enforce_sorted=False)\n",
    "        # \n",
    "        out, (hidden, cell) = self.rnn(out)\n",
    "        out = hidden[-1, :, :]\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "        \n",
    "model2 = RNN2(model1, vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size) \n",
    "model2 = model2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "d6e5b03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 accuracy: 0.8683 val_accuracy: 0.8665\n",
      "Epoch 1 accuracy: 0.8683 val_accuracy: 0.8665\n",
      "Epoch 2 accuracy: 0.8683 val_accuracy: 0.8665\n",
      "Epoch 3 accuracy: 0.8683 val_accuracy: 0.8665\n",
      "Epoch 4 accuracy: 0.8683 val_accuracy: 0.8665\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "torch.manual_seed(1)\n",
    " \n",
    "for epoch in range(num_epochs):\n",
    "    train(model1, train_dl, loss_fn, optimizer)\n",
    "    acc_train, loss_train = train(model2, train_dl, loss_fn, optimizer)\n",
    "    acc_valid, loss_valid = evaluate(model2, valid_dl, loss_fn, optimizer)\n",
    "    print(f'Epoch {epoch} accuracy: {acc_train:.4f} val_accuracy: {acc_valid:.4f}')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "9863e90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(4928, 24, padding_idx=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 1.1017, -0.1759, -2.2456,  ..., -1.0373,  1.5748, -0.6298],\n",
       "        [-0.9274,  0.5451,  0.0663,  ..., -0.0075,  1.6734,  0.0103],\n",
       "        ...,\n",
       "        [-2.5470,  0.4472,  1.2326,  ..., -1.1731, -0.8936,  0.6546],\n",
       "        [-1.1430, -1.4456, -1.2113,  ..., -1.2380, -0.1032,  1.8463],\n",
       "        [-1.4777, -0.0540, -1.4073,  ..., -1.6092,  0.5272,  1.4486]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model1.embedding)\n",
    "model1.embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "d81838ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(4928, 24, padding_idx=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 1.1017, -0.1759, -2.2456,  ..., -1.0373,  1.5748, -0.6298],\n",
       "        [-0.9274,  0.5451,  0.0663,  ..., -0.0075,  1.6734,  0.0103],\n",
       "        ...,\n",
       "        [-2.5470,  0.4472,  1.2326,  ..., -1.1731, -0.8936,  0.6546],\n",
       "        [-1.1430, -1.4456, -1.2113,  ..., -1.2380, -0.1032,  1.8463],\n",
       "        [-1.4777, -0.0540, -1.4073,  ..., -1.6092,  0.5272,  1.4486]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model2.embedding)\n",
    "model2.embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d6990c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f49535f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0056bb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "from collections import Counter, OrderedDict\n",
    "from torchtext.vocab import vocab\n",
    "\n",
    "class VocabSeq:\n",
    "    def __init__(self):\n",
    "        self.input =  Counter()\n",
    "        self.input_vocab = None\n",
    "        self.label =  Counter()\n",
    "        self.label_vocab = None\n",
    "    \n",
    "    def vocab(self, data_iter:Iterable):\n",
    "        # tokenizer\n",
    "        for seq_nt, labels in data_iter:\n",
    "            self.input.update(seq_nt)\n",
    "            self.label.update(labels)\n",
    "        # encode\n",
    "        self.encode_input()\n",
    "        self.encode_output()\n",
    "        return self.input_vocab, self.label_vocab\n",
    "    \n",
    "    def encode_input(self):\n",
    "        ordered_input = sorted(self.input.items(), key=lambda x: x[1], reverse=True)\n",
    "        ordered_input = OrderedDict(ordered_input)\n",
    "        self.input_vocab = vocab(ordered_input)\n",
    "        self.input_vocab.insert_token(\"<pad>\", 0)\n",
    "        self.input_vocab.insert_token(\"<unk>\", 1)\n",
    "        self.input_vocab.set_default_index(1)\n",
    "    \n",
    "    def encode_output(self):\n",
    "        ordered_label = sorted(self.label.items(), key=lambda x: x[1], reverse=True)\n",
    "        ordered_label = OrderedDict(ordered_label)\n",
    "        self.label_vocab = vocab(ordered_label)\n",
    "# \n",
    "coder = VocabSeq()\n",
    "data_iter = iterate_data(infile)\n",
    "input_vocab, label_vocab = coder.vocab(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b177b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "data_iter = iterate_data(infile)\n",
    "train_data = []\n",
    "for item in data_iter:\n",
    "    # input\n",
    "    input_vector = [input_vocab[i] for i in item[0]]\n",
    "    input_vector += [0] * (embedding_dim - len(input_vector))\n",
    "    # label\n",
    "    label_vector = [label_vocab[i] for i in item[1]]\n",
    "    #     \n",
    "    train_data.append((label_vector, input_vector))\n",
    "    \n",
    "num_train = round(len(train_data)*.8)\n",
    "num_valid = len(train_data) - num_train\n",
    "train_dataset, valid_dataset = random_split(train_data, [num_train, num_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7ba6357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39108 <class 'torch.utils.data.dataset.Subset'>\n",
      "([27, 10, 3, 13, 14, 8, 7, 8, 1, 5, 15, 0, 12, 18, 2, 0, 8], [2, 4, 4, 4, 3, 5, 2, 4, 3, 4, 2, 2, 4, 5, 5, 4, 4, 4, 3, 5, 4, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) 2\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset), type(train_dataset))\n",
    "print(train_dataset[0], len(train_dataset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d33f9be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the functions for transformation\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, lengths = [], [], []\n",
    "    for _label, _text in batch:\n",
    "        label_list.append(_label)\n",
    "        processed_text = torch.tensor(_text, dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        lengths.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    lengths = torch.tensor(lengths)\n",
    "    # padding is appended to the end of token vector of each sentence\n",
    "    padded_text_list = nn.utils.rnn.pad_sequence(text_list, batch_first=True)\n",
    "    return padded_text_list.to(device), label_list.to(device), lengths.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d19ccc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 17 at dim 1 (got 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(dataloader))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m##Observe data dimensions: Take a small batch\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m text_batch, label_batch, length_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput:\u001b[39m\u001b[38;5;124m'\u001b[39m, text_batch\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput:\u001b[39m\u001b[38;5;124m'\u001b[39m, label_batch)\n",
      "File \u001b[0;32m~/anaconda3/envs/py309/lib/python3.9/site-packages/torch/utils/data/dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 521\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/py309/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    560\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 561\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    563\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/py309/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:47\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[25], line 12\u001b[0m, in \u001b[0;36mcollate_batch\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     10\u001b[0m     text_list\u001b[38;5;241m.\u001b[39mappend(processed_text)\n\u001b[1;32m     11\u001b[0m     lengths\u001b[38;5;241m.\u001b[39mappend(processed_text\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m---> 12\u001b[0m label_list \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint64\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m lengths \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(lengths)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# padding is appended to the end of token vector of each sentence\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 17 at dim 1 (got 19)"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(train_dataset, batch_size=4, shuffle=False, collate_fn=collate_batch)\n",
    "print(type(dataloader))\n",
    "\n",
    "##Observe data dimensions: Take a small batch\n",
    "text_batch, label_batch, length_batch = next(iter(dataloader))\n",
    "print('input:', text_batch.shape)\n",
    "print('output:', label_batch)\n",
    "print('batch size=', length_batch)\n",
    "\n",
    "print(text_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "727df40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 4: batching the datasets. shuffle data for each epoch\n",
    "batch_size = 32\n",
    "\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "valid_dl = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71480cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, embed_dim, rnn_hidden_size, fc_hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_size, embed_dim, padding_idx=0) \n",
    "        # model: long-short term memory\n",
    "        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size, batch_first=True)\n",
    "        self.fc1 = nn.Linear(rnn_hidden_size, fc_hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(fc_hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, text, lengths):\n",
    "        out = self.embedding(text)\n",
    "        # Packs a Tensor containing padded sequences of variable length.\n",
    "        lengths = lengths.cpu().numpy()\n",
    "        out = nn.utils.rnn.pack_padded_sequence(out, lengths, batch_first=True, enforce_sorted=False)\n",
    "        # \n",
    "        out, (hidden, cell) = self.rnn(out)\n",
    "        out = hidden[-1, :, :]\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "         \n",
    "vocab_size = len(input_vocab)\n",
    "embed_dim = 20\n",
    "rnn_hidden_size = 64\n",
    "fc_hidden_size = 64\n",
    "\n",
    "torch.manual_seed(1)\n",
    "model = RNN(vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size) \n",
    "model = model.to(device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38e1ba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    total_acc, total_loss = 0, 0\n",
    "    for text_batch, label_batch, lengths in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(text_batch, lengths)[:, 0]\n",
    "        loss = loss_fn(pred, label_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_acc += ((pred>=0.5).float() == label_batch).float().sum().item()\n",
    "        total_loss += loss.item()*label_batch.size(0)\n",
    "    return total_acc/len(dataloader.dataset), total_loss/len(dataloader.dataset)\n",
    " \n",
    "def evaluate(dataloader, loss_fn, optimizer):\n",
    "    model.eval()\n",
    "    total_acc, total_loss = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for text_batch, label_batch, lengths in dataloader:\n",
    "            pred = model(text_batch, lengths)[:, 0]\n",
    "            loss = loss_fn(pred, label_batch)\n",
    "            total_acc += ((pred>=0.5).float() == label_batch).float().sum().item()\n",
    "            total_loss += loss.item()*label_batch.size(0)\n",
    "    return total_acc/len(dataloader.dataset), total_loss/len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "228278f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([32, 2])) that is different to the input size (torch.Size([32])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 9\u001b[0m     acc_train, loss_train \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     acc_valid, loss_valid \u001b[38;5;241m=\u001b[39m evaluate(valid_dl, loss_fn, optimizer)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc_train\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m val_accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc_valid\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[15], line 7\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      5\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      6\u001b[0m pred \u001b[38;5;241m=\u001b[39m model(text_batch, lengths)[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 7\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/anaconda3/envs/py309/lib/python3.9/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/py309/lib/python3.9/site-packages/torch/nn/modules/loss.py:612\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 612\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py309/lib/python3.9/site-packages/torch/nn/functional.py:2884\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2882\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[1;32m   2883\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize():\n\u001b[0;32m-> 2884\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2885\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a target size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) that is different to the input size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2886\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure they have the same size.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(target\u001b[38;5;241m.\u001b[39msize(), \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m   2887\u001b[0m     )\n\u001b[1;32m   2889\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2890\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n",
      "\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([32, 2])) that is different to the input size (torch.Size([32])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10 \n",
    "\n",
    "torch.manual_seed(1)\n",
    " \n",
    "for epoch in range(num_epochs):\n",
    "    acc_train, loss_train = train(train_dl, loss_fn, optimizer)\n",
    "    acc_valid, loss_valid = evaluate(valid_dl, loss_fn, optimizer)\n",
    "    print(f'Epoch {epoch} accuracy: {acc_train:.4f} val_accuracy: {acc_valid:.4f}')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5621f308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855ba711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404bb360",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from torch.utils.data import Dataset\n",
    "\n",
    "# class MirnaDataset(Dataset):\n",
    "#     def __init__(self, data, labels):\n",
    "#         self.data = data\n",
    "#         self.labels = labels\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         sample = self.data[idx]\n",
    "#         label = self.labels[idx]\n",
    "#         return sample, label\n",
    "# mirna_dataset = MirnaDataset(train_data, labels)\n",
    "# print(mirna_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
